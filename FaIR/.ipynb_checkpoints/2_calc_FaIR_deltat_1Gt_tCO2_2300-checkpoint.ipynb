{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b44309",
   "metadata": {},
   "source": [
    "## Script for generating temperature response to country-level emissions preturbation by way of FaIR\n",
    "#### Mustafa Zahid, 05/27/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618847cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing main packages as well as packages to generate the distributions \n",
    "# from which we will pull the sets of parameters\n",
    "from scipy.stats import lognorm, norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261a22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb9d0dd",
   "metadata": {},
   "source": [
    "### Part I: Generating climatic parameters (following Ashwin et al., 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55deba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the functions to generate distributions for our climate parameters (inputs in FaIR model)\n",
    "def lognorm_from_percentiles(x1, p1, x2, p2):\n",
    "    \"\"\" Return a log-normal distribuion X parametrized by:\n",
    "    \n",
    "            P(X < p1) = x1\n",
    "            P(X < p2) = x2\n",
    "    \"\"\"\n",
    "    x1 = np.log(x1)\n",
    "    x2 = np.log(x2)\n",
    "    p1ppf = norm.ppf(p1)\n",
    "    p2ppf = norm.ppf(p2)\n",
    "    \n",
    "    scale = (x2 - x1) / (p2ppf - p1ppf)\n",
    "    mean = ((x1 * p2ppf) - (x2 * p1ppf)) / (p2ppf - p1ppf)\n",
    "    \n",
    "    return np.random.lognormal(mean, scale, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb6047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49da4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the functions to generate distributions for our climate parameters (inputs in FaIR model)\n",
    "def norm_from_percentiles(x1, p1, x2, p2):\n",
    "    \"\"\" Return a normal distribuion X parametrized by:\n",
    "    \n",
    "            P(X < p1) = x1\n",
    "            P(X < p2) = x2\n",
    "    \"\"\"\n",
    "    p1ppf = norm.ppf(p1)\n",
    "    p2ppf = norm.ppf(p2)\n",
    "\n",
    "    location = ((x1 * p2ppf) - (x2 * p1ppf)) / (p2ppf - p1ppf)\n",
    "    scale = (x2 - x1) / (p2ppf - p1ppf)\n",
    "\n",
    "    return np.random.normal(location, scale, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3bdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b61fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now iterating over the parameters to pull from the distributions\n",
    "tcr = []\n",
    "rwf = []\n",
    "tau = []\n",
    "d2 = []\n",
    "ecs = []\n",
    "idi = []\n",
    "for i in range(1,101):\n",
    "        idi.append(i)\n",
    "        tcr.append(np.random.choice(lognorm_from_percentiles(1, 0.17, 2.5, 0.83)))\n",
    "        rwf.append(np.random.choice(norm_from_percentiles(0.45, 0.25, 0.75, 0.75)))\n",
    "        tau.append(np.random.choice(np.random.normal(4.03, 1.79, 1000)))\n",
    "        d2.append(np.random.choice(lognorm_from_percentiles(1.6, 0.05, 8.4, 0.95))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece898b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4aaeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate a dataframe and add the pulled parameters together\n",
    "df = pd.DataFrame()\n",
    "df[\"rwfnum\"] = rwf\n",
    "df[\"taunum\"] = tau\n",
    "df[\"tcrnum\"] = tcr\n",
    "df[\"d2num\"] = d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c8ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a514772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Ashwin et al., we restrict our parameters \n",
    "#tau\n",
    "df = df[df[\"taunum\"] > 0] \n",
    "df = df[df[\"taunum\"] < (2*3.95)]\n",
    "\n",
    "#rwf\n",
    "df = df[df[\"rwfnum\"] < 1]\n",
    "df = df[df[\"rwfnum\"] > np.percentile(df[\"rwfnum\"],6)]\n",
    "\n",
    "#ecs\n",
    "df[\"ecs\"] = df[\"tcrnum\"] / df[\"rwfnum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837abd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f30594ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate an ID for each of the sets of parameters\n",
    "df[\"idnum\"] = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343dae6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rwfnum</th>\n",
       "      <th>taunum</th>\n",
       "      <th>tcrnum</th>\n",
       "      <th>d2num</th>\n",
       "      <th>ecs</th>\n",
       "      <th>idnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833803</td>\n",
       "      <td>0.756244</td>\n",
       "      <td>1.824812</td>\n",
       "      <td>2.602927</td>\n",
       "      <td>2.188541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.372932</td>\n",
       "      <td>2.107678</td>\n",
       "      <td>1.840661</td>\n",
       "      <td>2.782466</td>\n",
       "      <td>4.935648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.901857</td>\n",
       "      <td>3.338227</td>\n",
       "      <td>1.835223</td>\n",
       "      <td>3.607538</td>\n",
       "      <td>2.034939</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.717555</td>\n",
       "      <td>3.715287</td>\n",
       "      <td>1.850146</td>\n",
       "      <td>3.776938</td>\n",
       "      <td>2.578403</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.784121</td>\n",
       "      <td>4.329783</td>\n",
       "      <td>2.807793</td>\n",
       "      <td>1.995077</td>\n",
       "      <td>3.580816</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.543251</td>\n",
       "      <td>2.009523</td>\n",
       "      <td>1.107382</td>\n",
       "      <td>3.180729</td>\n",
       "      <td>2.038437</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.656841</td>\n",
       "      <td>2.760988</td>\n",
       "      <td>0.721035</td>\n",
       "      <td>3.389485</td>\n",
       "      <td>1.097732</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.747611</td>\n",
       "      <td>2.458964</td>\n",
       "      <td>1.772201</td>\n",
       "      <td>4.110428</td>\n",
       "      <td>2.370484</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.498603</td>\n",
       "      <td>0.581262</td>\n",
       "      <td>0.651289</td>\n",
       "      <td>4.542115</td>\n",
       "      <td>1.306227</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.657487</td>\n",
       "      <td>5.396056</td>\n",
       "      <td>2.007932</td>\n",
       "      <td>3.813162</td>\n",
       "      <td>3.053949</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rwfnum    taunum    tcrnum     d2num       ecs  idnum\n",
       "0   0.833803  0.756244  1.824812  2.602927  2.188541      0\n",
       "2   0.372932  2.107678  1.840661  2.782466  4.935648      1\n",
       "3   0.901857  3.338227  1.835223  3.607538  2.034939      2\n",
       "4   0.717555  3.715287  1.850146  3.776938  2.578403      3\n",
       "5   0.784121  4.329783  2.807793  1.995077  3.580816      4\n",
       "..       ...       ...       ...       ...       ...    ...\n",
       "93  0.543251  2.009523  1.107382  3.180729  2.038437     83\n",
       "94  0.656841  2.760988  0.721035  3.389485  1.097732     84\n",
       "96  0.747611  2.458964  1.772201  4.110428  2.370484     85\n",
       "98  0.498603  0.581262  0.651289  4.542115  1.306227     86\n",
       "99  0.657487  5.396056  2.007932  3.813162  3.053949     87\n",
       "\n",
       "[88 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f999a9",
   "metadata": {},
   "source": [
    "### Part II: Running the FaIR model by iterating over emissions preturbation scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc6f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac90ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the needed libraries \n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from fair import *\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2f8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5961b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'long_term_emissions_data_new_ssp126.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gr/k0phdc4n6vbcrm736plhstzr0000gn/T/ipykernel_19487/1106291144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read the emissions country-year-level data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'long_term_emissions_data_new_ssp126.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"country_lvl_emms.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'long_term_emissions_data_new_ssp126.csv'"
     ]
    }
   ],
   "source": [
    "# read the emissions country-year-level data\n",
    "data = pd.read_csv('long_term_emissions_data_new_ssp126.csv')  \n",
    "data1 = pd.read_csv(\"country_lvl_emms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    " # The following function returns an empty dataframe in the correct format for use in FaIR.\n",
    "test_emissions = return_empty_emissions(df_to_copy=False, \n",
    "                                        start_year=0, \n",
    "                                        end_year=(120), \n",
    "                                        timestep=1, \n",
    "                                        scen_names=['Test'], \n",
    "                                        gases_in = ['carbon_dioxide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1571d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c9d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # create an empty forcing dataframe compatible with test_emissions:\n",
    "test_forcing = return_empty_forcing(test_emissions)\n",
    "\n",
    "    # Note that the scenario names in the emissions and forcing dataframe must be identical for \n",
    "    #the model to run: FaIR assumes each emissions scenario corresponds directly to a single forcing scenario.\n",
    "    \n",
    "    # Generate a default parameter dataframe:\n",
    "test_gas_parameters = get_gas_parameter_defaults()\n",
    "test_thermal_parameters = get_thermal_parameter_defaults()\n",
    "\n",
    "    # This is what the gas parameter dataframe looks like:\n",
    "test_gas_parameters.head()\n",
    "test_gas_parameters = test_gas_parameters.reindex(test_emissions.columns.levels[1],\n",
    "                                                  axis=1,\n",
    "                                                  level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4059aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34967676",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_isos = pd.unique(data1[\"ISO3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_isos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_array = np.array_split(list_of_isos, 200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c07ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_array[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5180852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff972387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = []\n",
    "for m in range(1,len(df)): \n",
    "    for i in range(1980,2100):\n",
    "        # shut off emissions from country i\n",
    "        data_iso = data1[data1[\"ISO3\"] == i]\n",
    "        data_iso = data_iso[[\"Year\", \"Total\"]]\n",
    "        data_iso.rename(columns = {'Total':'Total_iso'}, inplace = True)\n",
    "        data_new = pd.merge(data, data_iso, on = \"Year\")\n",
    "        data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]\n",
    "        data_new = data_new[[\"Year\", \"Total\"]]\n",
    "        data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data\n",
    "        data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "        data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "        # since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "        data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 \n",
    "        data_new = data_new[data_new[\"year\"] >= 1990].reset_index() # only keep 1980 and forward\n",
    "        data_new['year'] = data_new['year'] - (min(data_new['year']) - 1) \n",
    "        #feed updated emissions to test_emissions\n",
    "        test_emissions[(\"Test\", \"carbon_dioxide\")] = data_new['carbon_dioxide']\n",
    "        # test_gas_parameters[(\"default\", \"carbon_dioxide\")][6] = list(df1[\"taunum\"])[0]\n",
    "        \n",
    "        # therefore use central estimates for d1-3, q1; and set q2, q3 to return \"correct\" TCR/ECS values\n",
    "        df1 = df[df['idnum'] == m] \n",
    "        d1 = 0.903\n",
    "        d2 = list(df1[\"d2num\"])[0]\n",
    "        d3 = 355\n",
    "        q1 = 0.180\n",
    "        rwf = list(df1[\"rwfnum\"])[0]\n",
    "\n",
    "        TCR = list(df1[\"tcrnum\"])[0]\n",
    "        ECS = TCR / rwf\n",
    "        F_2x = 3.759\n",
    "\n",
    "        v1 = (1-(d1/69.66) * (1-np.exp(-69.66/d1)) )\n",
    "        v2 = (1-(d2/69.66) * (1-np.exp(-69.66/d2)) )\n",
    "        v3 = (1-(d3/69.66) * (1-np.exp(-69.66/d3)) )\n",
    "\n",
    "        q3 = (((TCR/F_2x) - q1*(v1-v2) - (ECS/F_2x)*v2) / (v3-v2))\n",
    "        q2 = (ECS/F_2x - q1 -  q3)\n",
    "\n",
    "        test_thermal_parameters[\"default\",2][1] = q2\n",
    "        test_thermal_parameters[\"default\",3][1] = q3\n",
    "\n",
    "            #test_thermal_parameters = pd.DataFrame([[d1,d2,d3],[q1,q2,q3]],\n",
    "             #                                      index=['d','q'],\n",
    "              #                                     columns=pd.MultiIndex.from_product([['default'],\n",
    "                      #                                                                 [1,2,3]]))\n",
    "        pulse_run = run_FaIR(emissions_in=test_emissions,\n",
    "                             forcing_in=test_forcing,\n",
    "                             gas_parameters=test_gas_parameters,\n",
    "                             thermal_parameters=test_thermal_parameters)\n",
    "        temp_response = pulse_run['T']\n",
    "        #(temp_response.temp_response).apply(lambda x: float(x))   \n",
    "            #temp_response[\"temp_response\"] = float(temp_response[\"temp_response\"]) \n",
    "            #temp_response.to_csv('temp_response/tempresponse' + \"_\" + str(k) + \"_\" + str(iso) + '.csv') \n",
    "        temp_response[\"loop\"] = str(m) + \"_loop_\" + i   \n",
    "        list_dfs.append(temp_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05016dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee330793",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_resp_k90_futusa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29628e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc95f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f2065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f0d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322dbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data\n",
    "data_new = data_new[[\"Year\", \"Total\"]]\n",
    "data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data\n",
    "data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "# since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new['carbon_dioxide'][120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data\n",
    "data_new = data_new[[\"Year\", \"Total\"]]\n",
    "data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data\n",
    "data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "# since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 \n",
    "data_new = data_new[data_new[\"year\"] >= 1980].reset_index() # only keep 1980 and forward\n",
    "data_new['year'] = data_new['year'] - (min(data_new['year']) - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"carbon_dioxide\"][120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac839292",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = []\n",
    "for m in range(1,len(df)): \n",
    "    for y in range(0,120):\n",
    "        \n",
    "      #  for i in master_array[9]:\n",
    "            # shut off emissions from country i\n",
    "    #        data_iso = data1[data1[\"ISO3\"] == i]\n",
    "     #       data_iso = data_iso[[\"Year\", \"Total\"]]\n",
    "      #      data_iso.rename(columns = {'Total':'Total_iso'}, inplace = True)\n",
    "       #     data_new = pd.merge(data, data_iso, on = \"Year\")\n",
    "        #    data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]\n",
    "        data_new = data\n",
    "        data_new = data_new[[\"Year\", \"Total\"]]\n",
    "        data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data\n",
    "        data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "        data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "        # since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "        data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 \n",
    "        data_new = data_new[data_new[\"year\"] >= 1980].reset_index() # only keep 1980 and forward\n",
    "        data_new['year'] = data_new['year'] - (min(data_new['year']) - 1) \n",
    "        data_new['carbon_dioxide'][y] = data_new['carbon_dioxide'][y] - 1\n",
    "        #feed updated emissions to test_emissions\n",
    "        test_emissions[(\"Test\", \"carbon_dioxide\")] = data_new['carbon_dioxide']\n",
    "            # test_gas_parameters[(\"default\", \"carbon_dioxide\")][6] = list(df1[\"taunum\"])[0]\n",
    "\n",
    "            # therefore use central estimates for d1-3, q1; and set q2, q3 to return \"correct\" TCR/ECS values\n",
    "        df1 = df[df['idnum'] == m] \n",
    "        d1 = 0.903\n",
    "        d2 = list(df1[\"d2num\"])[0]\n",
    "        d3 = 355\n",
    "        q1 = 0.180\n",
    "        rwf = list(df1[\"rwfnum\"])[0]\n",
    "\n",
    "        TCR = list(df1[\"tcrnum\"])[0]\n",
    "        ECS = TCR / rwf\n",
    "        F_2x = 3.759\n",
    "\n",
    "        v1 = (1-(d1/69.66) * (1-np.exp(-69.66/d1)) )\n",
    "        v2 = (1-(d2/69.66) * (1-np.exp(-69.66/d2)) )\n",
    "        v3 = (1-(d3/69.66) * (1-np.exp(-69.66/d3)) )\n",
    "\n",
    "        q3 = (((TCR/F_2x) - q1*(v1-v2) - (ECS/F_2x)*v2) / (v3-v2))\n",
    "        q2 = (ECS/F_2x - q1 -  q3)\n",
    "\n",
    "        test_thermal_parameters[\"default\",2][1] = q2\n",
    "        test_thermal_parameters[\"default\",3][1] = q3\n",
    "\n",
    "                #test_thermal_parameters = pd.DataFrame([[d1,d2,d3],[q1,q2,q3]],\n",
    "                 #                                      index=['d','q'],\n",
    "                  #                                     columns=pd.MultiIndex.from_product([['default'],\n",
    "                          #                                                                 [1,2,3]]))\n",
    "        pulse_run = run_FaIR(emissions_in=test_emissions,\n",
    "                             forcing_in=test_forcing,\n",
    "                             gas_parameters=test_gas_parameters,\n",
    "                             thermal_parameters=test_thermal_parameters)\n",
    "        temp_response = pulse_run['T']\n",
    "            #(temp_response.temp_response).apply(lambda x: float(x))   \n",
    "                #temp_response[\"temp_response\"] = float(temp_response[\"temp_response\"]) \n",
    "                #temp_response.to_csv('temp_response/tempresponse' + \"_\" + str(k) + \"_\" + str(iso) + '.csv') \n",
    "        temp_response[\"loop\"] = str(m) + \"_\" + str(y + 1980)+ \"_loop_all\" \n",
    "        list_dfs.append(temp_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_resp_k80_1GtC_hist_fut.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0051c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59849ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = []\n",
    "for m in range(1,len(df)):         \n",
    "      #  for i in master_array[9]:\n",
    "            # shut off emissions from country i\n",
    "    #        data_iso = data1[data1[\"ISO3\"] == i]\n",
    "     #       data_iso = data_iso[[\"Year\", \"Total\"]]\n",
    "      #      data_iso.rename(columns = {'Total':'Total_iso'}, inplace = True)\n",
    "       #     data_new = pd.merge(data, data_iso, on = \"Year\")\n",
    "        #    data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]\n",
    "    data_new = data\n",
    "    data_new = data_new[[\"Year\", \"Total\"]]\n",
    "    data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data\n",
    "    data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "    data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "        # since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "    data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 \n",
    "    data_new = data_new[data_new[\"year\"] >= 1980].reset_index() # only keep 1980 and forward\n",
    "    data_new['year'] = data_new['year'] - (min(data_new['year']) - 1) \n",
    "#    data_new['carbon_dioxide'][y] = data_new['carbon_dioxide'][y] - 1\n",
    "        #feed updated emissions to test_emissions\n",
    "    test_emissions[(\"Test\", \"carbon_dioxide\")] = data_new['carbon_dioxide']\n",
    "            # test_gas_parameters[(\"default\", \"carbon_dioxide\")][6] = list(df1[\"taunum\"])[0]\n",
    "\n",
    "            # therefore use central estimates for d1-3, q1; and set q2, q3 to return \"correct\" TCR/ECS values\n",
    "    df1 = df[df['idnum'] == m] \n",
    "    d1 = 0.903\n",
    "    d2 = list(df1[\"d2num\"])[0]\n",
    "    d3 = 355\n",
    "    q1 = 0.180\n",
    "    rwf = list(df1[\"rwfnum\"])[0]\n",
    "\n",
    "    TCR = list(df1[\"tcrnum\"])[0]\n",
    "    ECS = TCR / rwf\n",
    "    F_2x = 3.759\n",
    "\n",
    "    v1 = (1-(d1/69.66) * (1-np.exp(-69.66/d1)) )\n",
    "    v2 = (1-(d2/69.66) * (1-np.exp(-69.66/d2)) )\n",
    "    v3 = (1-(d3/69.66) * (1-np.exp(-69.66/d3)) )\n",
    "\n",
    "    q3 = (((TCR/F_2x) - q1*(v1-v2) - (ECS/F_2x)*v2) / (v3-v2))\n",
    "    q2 = (ECS/F_2x - q1 -  q3)\n",
    "\n",
    "    test_thermal_parameters[\"default\",2][1] = q2\n",
    "    test_thermal_parameters[\"default\",3][1] = q3\n",
    "\n",
    "                #test_thermal_parameters = pd.DataFrame([[d1,d2,d3],[q1,q2,q3]],\n",
    "                 #                                      index=['d','q'],\n",
    "                  #                                     columns=pd.MultiIndex.from_product([['default'],\n",
    "                          #                                                                 [1,2,3]]))\n",
    "    pulse_run = run_FaIR(emissions_in=test_emissions,\n",
    "                         forcing_in=test_forcing,\n",
    "                         gas_parameters=test_gas_parameters,\n",
    "                         thermal_parameters=test_thermal_parameters)\n",
    "    temp_response = pulse_run['T']\n",
    "            #(temp_response.temp_response).apply(lambda x: float(x))   \n",
    "                #temp_response[\"temp_response\"] = float(temp_response[\"temp_response\"]) \n",
    "                #temp_response.to_csv('temp_response/tempresponse' + \"_\" + str(k) + \"_\" + str(iso) + '.csv') \n",
    "    temp_response[\"loop\"] = str(m) + \"_loop_all\" \n",
    "    list_dfs.append(temp_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75fd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_resp_k80_full_hist_fut.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d28e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fae81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ad111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff3264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_response_1980_2020_nousa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_response_1750_2100_test_min11980.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('long_term_emissions_data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"country_lvl_emms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zwe = data1[data1[\"ISO3\"] == \"ZWE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807738b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zwe = data_zwe[[\"Year\", \"Total\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zwe.rename(columns = {'Total':'Total_iso'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.merge(data, data_zwe, on = \"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
