{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b44309",
   "metadata": {},
   "source": [
    "## Script for generating temperature response to country-level emissions preturbation by way of FaIR\n",
    "#### Mustafa Zahid, 05/27/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618847cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing main packages as well as packages to generate the distributions \n",
    "# from which we will pull the sets of parameters\n",
    "from scipy.stats import lognorm, norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261a22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb9d0dd",
   "metadata": {},
   "source": [
    "### Part I: Generating climatic parameters (following Ashwin et al., 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55deba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the functions to generate distributions for our climate parameters (inputs in FaIR model)\n",
    "def lognorm_from_percentiles(x1, p1, x2, p2):\n",
    "    \"\"\" Return a log-normal distribuion X parametrized by:\n",
    "    \n",
    "            P(X < p1) = x1\n",
    "            P(X < p2) = x2\n",
    "    \"\"\"\n",
    "    x1 = np.log(x1)\n",
    "    x2 = np.log(x2)\n",
    "    p1ppf = norm.ppf(p1)\n",
    "    p2ppf = norm.ppf(p2)\n",
    "    \n",
    "    scale = (x2 - x1) / (p2ppf - p1ppf)\n",
    "    mean = ((x1 * p2ppf) - (x2 * p1ppf)) / (p2ppf - p1ppf)\n",
    "    \n",
    "    return np.random.lognormal(mean, scale, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb6047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the functions to generate distributions for our climate parameters (inputs in FaIR model)\n",
    "def norm_from_percentiles(x1, p1, x2, p2):\n",
    "    \"\"\" Return a normal distribuion X parametrized by:\n",
    "    \n",
    "            P(X < p1) = x1\n",
    "            P(X < p2) = x2\n",
    "    \"\"\"\n",
    "    p1ppf = norm.ppf(p1)\n",
    "    p2ppf = norm.ppf(p2)\n",
    "\n",
    "    location = ((x1 * p2ppf) - (x2 * p1ppf)) / (p2ppf - p1ppf)\n",
    "    scale = (x2 - x1) / (p2ppf - p1ppf)\n",
    "\n",
    "    return np.random.normal(location, scale, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3bdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now iterating over the parameters to pull from the distributions\n",
    "tcr = []\n",
    "rwf = []\n",
    "tau = []\n",
    "d2 = []\n",
    "ecs = []\n",
    "idi = []\n",
    "for i in range(1,101):\n",
    "        idi.append(i)\n",
    "        tcr.append(np.random.choice(lognorm_from_percentiles(1, 0.17, 2.5, 0.83)))\n",
    "        rwf.append(np.random.choice(norm_from_percentiles(0.45, 0.25, 0.75, 0.75)))\n",
    "        tau.append(np.random.choice(np.random.normal(4.03, 1.79, 1000)))\n",
    "        d2.append(np.random.choice(lognorm_from_percentiles(1.6, 0.05, 8.4, 0.95))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece898b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aaeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate a dataframe and add the pulled parameters together\n",
    "df = pd.DataFrame()\n",
    "df[\"rwfnum\"] = rwf\n",
    "df[\"taunum\"] = tau\n",
    "df[\"tcrnum\"] = tcr\n",
    "df[\"d2num\"] = d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c8ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a514772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Ashwin et al., we restrict our parameters \n",
    "#tau\n",
    "df = df[df[\"taunum\"] > 0] \n",
    "df = df[df[\"taunum\"] < (2*3.95)]\n",
    "\n",
    "#rwf\n",
    "df = df[df[\"rwfnum\"] < 1]\n",
    "df = df[df[\"rwfnum\"] > np.percentile(df[\"rwfnum\"],6)]\n",
    "\n",
    "#ecs\n",
    "df[\"ecs\"] = df[\"tcrnum\"] / df[\"rwfnum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837abd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30594ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate an ID for each of the sets of parameters\n",
    "df[\"idnum\"] = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343dae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f999a9",
   "metadata": {},
   "source": [
    "### Part II: Running the FaIR model by iterating over emissions preturbation scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc6f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac90ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the needed libraries \n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from fair import *\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2f8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5961b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the emissions country-year-level data\n",
    "data = pd.read_csv('long_term_emissions_data_new.csv')  \n",
    "data1 = pd.read_csv(\"country_lvl_emms_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    " # The following function returns an empty dataframe in the correct format for use in FaIR.\n",
    "test_emissions = return_empty_emissions(df_to_copy=False, \n",
    "                                        start_year=0, \n",
    "                                        end_year=(120), \n",
    "                                        timestep=1, \n",
    "                                        scen_names=['Test'], \n",
    "                                        gases_in = ['carbon_dioxide'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1571d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c9d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # create an empty forcing dataframe compatible with test_emissions:\n",
    "test_forcing = return_empty_forcing(test_emissions)\n",
    "\n",
    "    # Note that the scenario names in the emissions and forcing dataframe must be identical for \n",
    "    #the model to run: FaIR assumes each emissions scenario corresponds directly to a single forcing scenario.\n",
    "    \n",
    "    # Generate a default parameter dataframe:\n",
    "test_gas_parameters = get_gas_parameter_defaults()\n",
    "test_thermal_parameters = get_thermal_parameter_defaults()\n",
    "\n",
    "    # This is what the gas parameter dataframe looks like:\n",
    "test_gas_parameters.head()\n",
    "test_gas_parameters = test_gas_parameters.reindex(test_emissions.columns.levels[1],\n",
    "                                                  axis=1,\n",
    "                                                  level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4059aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34967676",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_isos = pd.unique(data1[\"ISO3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_isos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_array = np.array_split(list_of_isos, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c07ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_array[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5180852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff972387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = []\n",
    "for m in range(1,len(df)): \n",
    "    for i in master_array[9]:\n",
    "        # shut off emissions from country i\n",
    "        data_iso = data1[data1[\"ISO3\"] == i]\n",
    "        data_iso = data_iso[[\"Year\", \"Total\"]]\n",
    "        data_iso.rename(columns = {'Total':'Total_iso'}, inplace = True)\n",
    "        data_new = pd.merge(data, data_iso, on = \"Year\")\n",
    "        data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]\n",
    "        data_new = data_new[[\"Year\", \"Total\"]]\n",
    "        data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data\n",
    "        data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "        data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "        # since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "        data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 \n",
    "        data_new = data_new[data_new[\"year\"] >= 1980].reset_index() # only keep 1980 and forward\n",
    "        data_new['year'] = data_new['year'] - (min(data_new['year']) - 1) \n",
    "        #feed updated emissions to test_emissions\n",
    "        test_emissions[(\"Test\", \"carbon_dioxide\")] = data_new['carbon_dioxide']\n",
    "        # test_gas_parameters[(\"default\", \"carbon_dioxide\")][6] = list(df1[\"taunum\"])[0]\n",
    "        \n",
    "        # therefore use central estimates for d1-3, q1; and set q2, q3 to return \"correct\" TCR/ECS values\n",
    "        df1 = df[df['idnum'] == m] \n",
    "        d1 = 0.903\n",
    "        d2 = list(df1[\"d2num\"])[0]\n",
    "        d3 = 355\n",
    "        q1 = 0.180\n",
    "        rwf = list(df1[\"rwfnum\"])[0]\n",
    "\n",
    "        TCR = list(df1[\"tcrnum\"])[0]\n",
    "        ECS = TCR / rwf\n",
    "        F_2x = 3.759\n",
    "\n",
    "        v1 = (1-(d1/69.66) * (1-np.exp(-69.66/d1)) )\n",
    "        v2 = (1-(d2/69.66) * (1-np.exp(-69.66/d2)) )\n",
    "        v3 = (1-(d3/69.66) * (1-np.exp(-69.66/d3)) )\n",
    "\n",
    "        q3 = (((TCR/F_2x) - q1*(v1-v2) - (ECS/F_2x)*v2) / (v3-v2))\n",
    "        q2 = (ECS/F_2x - q1 -  q3)\n",
    "\n",
    "        test_thermal_parameters[\"default\",2][1] = q2\n",
    "        test_thermal_parameters[\"default\",3][1] = q3\n",
    "\n",
    "            #test_thermal_parameters = pd.DataFrame([[d1,d2,d3],[q1,q2,q3]],\n",
    "             #                                      index=['d','q'],\n",
    "              #                                     columns=pd.MultiIndex.from_product([['default'],\n",
    "                      #                                                                 [1,2,3]]))\n",
    "        pulse_run = run_FaIR(emissions_in=test_emissions,\n",
    "                             forcing_in=test_forcing,\n",
    "                             gas_parameters=test_gas_parameters,\n",
    "                             thermal_parameters=test_thermal_parameters)\n",
    "        temp_response = pulse_run['T']\n",
    "        #(temp_response.temp_response).apply(lambda x: float(x))   \n",
    "            #temp_response[\"temp_response\"] = float(temp_response[\"temp_response\"]) \n",
    "            #temp_response.to_csv('temp_response/tempresponse' + \"_\" + str(k) + \"_\" + str(iso) + '.csv') \n",
    "        temp_response[\"loop\"] = str(m) + \"_loop_\" + i   \n",
    "        list_dfs.append(temp_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs[1].to_csv(\"alb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05016dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee330793",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_resp_k90_hist_fut9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iso = data1[data1[\"ISO3\"] == \"ALB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc95f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iso = data_iso[[\"Year\", \"Total\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iso.rename(columns = {'Total':'Total_iso'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.merge(data, data_iso, on = \"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data_new[[\"Year\", \"Total\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "        # since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 \n",
    "data_new = data_new[data_new[\"year\"] >= 1980].reset_index() # only keep 1980 and forward\n",
    "data_new['year'] = data_new['year'] - (min(data_new['year']) - 1) \n",
    "        #feed updated emissions to test_emissions\n",
    "test_emissions[(\"Test\", \"carbon_dioxide\")] = data_new['carbon_dioxide']\n",
    "        # test_gas_parameters[(\"default\", \"carbon_dioxide\")][6] = list(df1[\"ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac839292",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs = []\n",
    "for m in range(1,len(df)): \n",
    "  #  for i in master_array[9]:\n",
    "        # shut off emissions from country i\n",
    "#        data_iso = data1[data1[\"ISO3\"] == i]\n",
    " #       data_iso = data_iso[[\"Year\", \"Total\"]]\n",
    "  #      data_iso.rename(columns = {'Total':'Total_iso'}, inplace = True)\n",
    "   #     data_new = pd.merge(data, data_iso, on = \"Year\")\n",
    "    #    data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]\n",
    "    data_new = data\n",
    "    data_new = data_new[[\"Year\", \"Total\"]]\n",
    "    data_new.rename(columns = {'Total':'carbon_dioxide'}, inplace = True) #change name to match emissions data\n",
    "    data_new.rename(columns = {'Year':'year'}, inplace = True) #change name to match emissions data\n",
    "    data_new[\"year\"] = pd.to_numeric(data_new[\"year\"]) \n",
    "    # since the carbon emissions are on MtCO2, we need to convert to GtC\n",
    "    data_new['carbon_dioxide'] = (data_new['carbon_dioxide'] / 1000) / 3.67 \n",
    "    data_new = data_new[data_new[\"year\"] >= 1980].reset_index() # only keep 1980 and forward\n",
    "    data_new['year'] = data_new['year'] - (min(data_new['year']) - 1) \n",
    "    #feed updated emissions to test_emissions\n",
    "    test_emissions[(\"Test\", \"carbon_dioxide\")] = data_new['carbon_dioxide']\n",
    "        # test_gas_parameters[(\"default\", \"carbon_dioxide\")][6] = list(df1[\"taunum\"])[0]\n",
    "        \n",
    "        # therefore use central estimates for d1-3, q1; and set q2, q3 to return \"correct\" TCR/ECS values\n",
    "    df1 = df[df['idnum'] == m] \n",
    "    d1 = 0.903\n",
    "    d2 = list(df1[\"d2num\"])[0]\n",
    "    d3 = 355\n",
    "    q1 = 0.180\n",
    "    rwf = list(df1[\"rwfnum\"])[0]\n",
    "\n",
    "    TCR = list(df1[\"tcrnum\"])[0]\n",
    "    ECS = TCR / rwf\n",
    "    F_2x = 3.759\n",
    "\n",
    "    v1 = (1-(d1/69.66) * (1-np.exp(-69.66/d1)) )\n",
    "    v2 = (1-(d2/69.66) * (1-np.exp(-69.66/d2)) )\n",
    "    v3 = (1-(d3/69.66) * (1-np.exp(-69.66/d3)) )\n",
    "\n",
    "    q3 = (((TCR/F_2x) - q1*(v1-v2) - (ECS/F_2x)*v2) / (v3-v2))\n",
    "    q2 = (ECS/F_2x - q1 -  q3)\n",
    "\n",
    "    test_thermal_parameters[\"default\",2][1] = q2\n",
    "    test_thermal_parameters[\"default\",3][1] = q3\n",
    "\n",
    "            #test_thermal_parameters = pd.DataFrame([[d1,d2,d3],[q1,q2,q3]],\n",
    "             #                                      index=['d','q'],\n",
    "              #                                     columns=pd.MultiIndex.from_product([['default'],\n",
    "                      #                                                                 [1,2,3]]))\n",
    "    pulse_run = run_FaIR(emissions_in=test_emissions,\n",
    "                         forcing_in=test_forcing,\n",
    "                         gas_parameters=test_gas_parameters,\n",
    "                         thermal_parameters=test_thermal_parameters)\n",
    "    temp_response = pulse_run['T']\n",
    "        #(temp_response.temp_response).apply(lambda x: float(x))   \n",
    "            #temp_response[\"temp_response\"] = float(temp_response[\"temp_response\"]) \n",
    "            #temp_response.to_csv('temp_response/tempresponse' + \"_\" + str(k) + \"_\" + str(iso) + '.csv') \n",
    "    temp_response[\"loop\"] = str(m) + \"_loop_all\" \n",
    "    list_dfs.append(temp_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_resp_k90_hist_futall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0051c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59849ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d9bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75fd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d28e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fae81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ad111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff3264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_response_1980_2020_nousa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(list_dfs).to_csv(\"fair_temp_response_1750_2100_test_min11980.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('long_term_emissions_data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"country_lvl_emms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zwe = data1[data1[\"ISO3\"] == \"ZWE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807738b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zwe = data_zwe[[\"Year\", \"Total\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zwe.rename(columns = {'Total':'Total_iso'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.merge(data, data_zwe, on = \"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"Total\"] = data_new[\"Total\"] - data_new[\"Total_iso\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
